import streamlit as st
import pandas as pd
import google.generativeai as genai
from PIL import Image
import requests

# ====== é é¢è¨­å®š ======
st.set_page_config(page_title="ğŸ§  è³‡æ–™åˆ†æ + Gemini å°è©±", page_icon="ğŸ“Š", layout="wide")

# ====== API é‡‘é‘°è¨­å®š ======
# ğŸš¨ è«‹æ›¿æ›ç‚ºä½ è‡ªå·±çš„ Gemini API é‡‘é‘°
genai.configure(api_key="AIzaSyBcTohvzAeRE71-GIfCD9sfFsvYf403h8w")

# ====== ğŸ”’ å´é‚Šæ¬„é¸å–® ======
with st.sidebar:
    st.header("ğŸ”§ å·¥å…·é¸å–®")
    app_mode = st.radio("é¸æ“‡åŠŸèƒ½é ", ["ğŸ“Š è³‡æ–™é›†åˆ†æ", "ğŸ¤– Gemini èŠå¤©æ©Ÿå™¨äºº"])

    st.markdown("---")
    st.header("ğŸ¨ ä¸»é¡Œè¨­å®š")
    theme = st.selectbox("é¸æ“‡ä¸»é¡Œè‰²", ["æ·ºè‰²", "æ·±è‰²"])

    if app_mode == "ğŸ“Š è³‡æ–™é›†åˆ†æ":
        show_preview = st.checkbox("é¡¯ç¤ºè³‡æ–™é è¦½", value=True)
        num_rows = st.slider("é¡¯ç¤ºå¹¾åˆ—è³‡æ–™", min_value=5, max_value=100, value=10)
        st.info("è«‹ä¸Šå‚³ CSV æª”æ¡ˆã€‚")

# ====== ä¸»é¡Œæ¨£å¼åˆ‡æ› ======
if theme == "æ·±è‰²":
    st.markdown("""
        <style>
        .stApp {
            background-color: #000000;
            color: white;
        }
        section[data-testid="stSidebar"] {
            background-color: #111111;
            color: white;
        }
        h1, h2, h3, h4, h5, h6, p {
            color: white !important;
        }
        .dataframe th, .dataframe td {
            color: white !important;
        }
        </style>
    """, unsafe_allow_html=True)
else:
    st.markdown("""
        <style>
        .stApp {
            background-color: #ffffff;
            color: black;
        }
        section[data-testid="stSidebar"] {
            background-color: #f0f2f6;
            color: black;
        }
        </style>
    """, unsafe_allow_html=True)

# ====== åŠŸèƒ½ 1: è³‡æ–™é›†åˆ†æ ======
if app_mode == "ğŸ“Š è³‡æ–™é›†åˆ†æ":
    st.title("HW.1")
    st.markdown("ä¸Šå‚³ä¸€å€‹ Kaggle æˆ–å…¶ä»–ä¾†æºçš„ `.csv` æª”æ¡ˆï¼Œé€²è¡Œè³‡æ–™é è¦½èˆ‡ç°¡æ˜“åˆ†æã€‚")

    uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šå‚³ä½ çš„ CSV æª”æ¡ˆ", type=["csv"])

    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            st.success("âœ… æˆåŠŸè¼‰å…¥è³‡æ–™ï¼")

            if show_preview:
                tab1, tab2, tab3 = st.tabs(["ğŸ” è³‡æ–™é è¦½", "ğŸ“Š æ•˜è¿°çµ±è¨ˆ", "ğŸ§© æ¬„ä½ç¯©é¸"])

                with tab1:
                    st.subheader("ğŸ” é è¦½å‰å¹¾åˆ—")
                    st.dataframe(df.head(num_rows), use_container_width=True)

                with tab2:
                    st.subheader("ğŸ“Š è³‡æ–™æ•˜è¿°çµ±è¨ˆ")
                    st.write(df.describe())

                with tab3:
                    st.subheader("ğŸ§© æ¬„ä½ç¯©é¸å™¨")
                    column = st.selectbox("è«‹é¸æ“‡è¦é¡¯ç¤ºçš„æ¬„ä½", df.columns)
                    st.dataframe(df[[column]].head(num_rows), use_container_width=True)
            else:
                st.warning("ğŸ“Œ è³‡æ–™å…§å®¹ç›®å‰å·²è¢«éš±è—ã€‚è«‹åœ¨å·¦å´å‹¾é¸ã€é¡¯ç¤ºè³‡æ–™é è¦½ã€æŸ¥çœ‹è³‡æ–™ã€‚")

        except Exception as e:
            st.error(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–æª”æ¡ˆï¼Œè«‹ç¢ºèªæ ¼å¼æ­£ç¢ºã€‚\n\n{e}")
    else:
        st.warning("ğŸ“Œ è«‹ä¸Šå‚³ä¸€å€‹ `.csv` æª”æ¡ˆã€‚")

# ====== åŠŸèƒ½ 2: Gemini èŠå¤©æ©Ÿå™¨äºº ======
elif app_mode == "ğŸ¤– Gemini èŠå¤©æ©Ÿå™¨äºº":
    st.title("ğŸ¤– Gemini Chatbot")
    st.markdown("è«‹è¼¸å…¥ä»»ä½•å•é¡Œï¼ŒGemini å°‡æœƒå›æ‡‰ä½ ã€‚")

    user_input = st.text_area("âœï¸ ä½ æƒ³å• Gemini ä»€éº¼ï¼Ÿ", height=150)

    if st.button("ğŸš€ é€å‡º"):
        if user_input.strip() == "":
            st.warning("è«‹è¼¸å…¥å•é¡Œå¾Œå†é€å‡ºã€‚")
        elif len(user_input) > 1000:
            st.warning("âš ï¸ è¼¸å…¥éé•·ï¼Œè«‹ç°¡åŒ–ä½ çš„å•é¡Œï¼ˆæœ€å¤š 1000 å­—å…ƒï¼‰ã€‚")
        else:
            with st.spinner("Gemini æ­£åœ¨ç”Ÿæˆå›æ‡‰..."):
                try:
                    model = genai.GenerativeModel("models/gemini-1.5-flash")
                    response = model.generate_content(user_input, stream=True)

                    st.success("âœ… Gemini å›æ‡‰ï¼š")
                    full_response = ""
                    for chunk in response:
                        if chunk.text:
                            full_response += chunk.text
                            st.markdown(chunk.text)

                except requests.exceptions.Timeout:
                    st.error("â° è«‹æ±‚é€¾æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                except Exception as e:
                    st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
